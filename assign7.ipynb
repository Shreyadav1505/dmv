{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04d92d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2. Loading Data ---\n",
      "Initial CSV Data:\n",
      "          Date ProductID  Amount Region\n",
      "0  2024-01-01      P100     150  North\n",
      "1  2024-01-02      P101     200  South\n",
      "2  2024-01-01      P100     150  North\n",
      "3  2024-01-04      P102     500   West\n",
      "\n",
      "Initial Excel Data:\n",
      "     OrderDate ItemCode  Sales   Area\n",
      "0  2024-01-05     P103  300.0   East\n",
      "1  2024-01-06     P102  500.0   West\n",
      "2  2024-01-07     P104    NaN  South\n",
      "\n",
      "Initial JSON Data:\n",
      "         date product_id  total location\n",
      "0 2024-01-08       P101    200    South\n",
      "1 2024-01-09       P105    120    North\n",
      "------------------------------\n",
      "\n",
      "--- 3. Exploring Data ---\n",
      "\n",
      "CSV Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4 entries, 0 to 3\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Date       4 non-null      object\n",
      " 1   ProductID  4 non-null      object\n",
      " 2   Amount     4 non-null      int64 \n",
      " 3   Region     4 non-null      object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 260.0+ bytes\n",
      "\n",
      "Excel Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   OrderDate  3 non-null      object \n",
      " 1   ItemCode   3 non-null      object \n",
      " 2   Sales      2 non-null      float64\n",
      " 3   Area       3 non-null      object \n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 228.0+ bytes\n",
      "\n",
      "JSON Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2 entries, 0 to 1\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   date        2 non-null      datetime64[ns]\n",
      " 1   product_id  2 non-null      object        \n",
      " 2   total       2 non-null      int64         \n",
      " 3   location    2 non-null      object        \n",
      "dtypes: datetime64[ns](1), int64(1), object(2)\n",
      "memory usage: 196.0+ bytes\n",
      "\n",
      "Identified Issues:\n",
      "1. Inconsistent column names (e.g., 'Amount', 'Sales', 'total')\n",
      "2. Inconsistent column names (e.g., 'Region', 'Area', 'location')\n",
      "3. Missing values found in Excel data:\n",
      "OrderDate    0\n",
      "ItemCode     0\n",
      "Sales        1\n",
      "Area         0\n",
      "dtype: int64\n",
      "4. Duplicate rows found in CSV data.\n",
      "5. Date columns are 'object' type, not 'datetime'.\n",
      "------------------------------\n",
      "\n",
      "--- 4. Cleaning and Standardizing ---\n",
      "CSV data cleaned.\n",
      "Excel data cleaned.\n",
      "JSON data cleaned.\n",
      "------------------------------\n",
      "\n",
      "--- 5. Unifying Data ---\n",
      "\n",
      "--- Final Unified Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7 entries, 0 to 6\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype         \n",
      "---  ------     --------------  -----         \n",
      " 0   Date       7 non-null      datetime64[ns]\n",
      " 1   ProductID  7 non-null      object        \n",
      " 2   Amount     7 non-null      int64         \n",
      " 3   Region     7 non-null      object        \n",
      "dtypes: datetime64[ns](1), int64(1), object(2)\n",
      "memory usage: 356.0+ bytes\n",
      "\n",
      "--- Final Unified Head ---\n",
      "        Date ProductID  Amount Region\n",
      "0 2024-01-01      P100     150  North\n",
      "1 2024-01-02      P101     200  South\n",
      "2 2024-01-04      P102     500   West\n",
      "3 2024-01-05      P103     300   East\n",
      "4 2024-01-06      P102     500   West\n",
      "5 2024-01-08      P101     200  South\n",
      "6 2024-01-09      P105     120  North\n",
      "\n",
      "--- Final Descriptive Statistics ---\n",
      "                      Date      Amount\n",
      "count                    7    7.000000\n",
      "mean   2024-01-05 00:00:00  281.428571\n",
      "min    2024-01-01 00:00:00  120.000000\n",
      "25%    2024-01-03 00:00:00  175.000000\n",
      "50%    2024-01-05 00:00:00  200.000000\n",
      "75%    2024-01-07 00:00:00  400.000000\n",
      "max    2024-01-09 00:00:00  500.000000\n",
      "std                    NaN  159.418586\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "\n",
    "# --- 1. Simulate File Data ---\n",
    "# In a real-world scenario, you would replace the io.StringIO/io.BytesIO\n",
    "# objects with your actual file paths (e.g., 'sales.csv', 'data.xlsx')\n",
    "\n",
    "# Sample CSV data\n",
    "csv_data = \"\"\"Date,ProductID,Amount,Region\n",
    "2024-01-01,P100,150,North\n",
    "2024-01-02,P101,200,South\n",
    "2024-01-01,P100,150,North\n",
    "2024-01-04,P102,500,West\n",
    "\"\"\"\n",
    "\n",
    "# Sample Excel data\n",
    "excel_data = {\n",
    "    'OrderDate': ['2024-01-05', '2024-01-06', '2024-01-07'],\n",
    "    'ItemCode': ['P103', 'P102', 'P104'],\n",
    "    'Sales': [300, 500, np.nan], # Missing value\n",
    "    'Area': ['East', 'West', 'South']\n",
    "}\n",
    "# Create an in-memory Excel file\n",
    "excel_file = io.BytesIO()\n",
    "pd.DataFrame(excel_data).to_excel(excel_file, index=False, engine='openpyxl')\n",
    "excel_file.seek(0) # Rewind the file to the beginning\n",
    "\n",
    "# Sample JSON data (record-oriented)\n",
    "json_data = \"\"\"\n",
    "[\n",
    "  {\"date\": \"2024-01-08\", \"product_id\": \"P101\", \"total\": 200, \"location\": \"South\"},\n",
    "  {\"date\": \"2024-01-09\", \"product_id\": \"P105\", \"total\": 120, \"location\": \"North\"}\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "# --- 2. Load Data into DataFrames ---\n",
    "\n",
    "print(\"--- 2. Loading Data ---\")\n",
    "# Load CSV\n",
    "df_csv = pd.read_csv(io.StringIO(csv_data))\n",
    "# Load Excel\n",
    "df_excel = pd.read_excel(excel_file, engine='openpyxl')\n",
    "# Load JSON\n",
    "df_json = pd.read_json(io.StringIO(json_data))\n",
    "\n",
    "print(\"Initial CSV Data:\\n\", df_csv.head())\n",
    "print(\"\\nInitial Excel Data:\\n\", df_excel.head())\n",
    "print(\"\\nInitial JSON Data:\\n\", df_json.head())\n",
    "print(\"-\" * 30)\n",
    "\n",
    "\n",
    "# --- 3. Explore and Identify Issues ---\n",
    "\n",
    "print(\"\\n--- 3. Exploring Data ---\")\n",
    "print(\"\\nCSV Info:\")\n",
    "df_csv.info()\n",
    "print(\"\\nExcel Info:\")\n",
    "df_excel.info()\n",
    "print(\"\\nJSON Info:\")\n",
    "df_json.info()\n",
    "\n",
    "print(\"\\nIdentified Issues:\")\n",
    "print(\"1. Inconsistent column names (e.g., 'Amount', 'Sales', 'total')\")\n",
    "print(\"2. Inconsistent column names (e.g., 'Region', 'Area', 'location')\")\n",
    "print(\"3. Missing values found in Excel data:\")\n",
    "print(df_excel.isnull().sum())\n",
    "print(\"4. Duplicate rows found in CSV data.\")\n",
    "print(\"5. Date columns are 'object' type, not 'datetime'.\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "\n",
    "# --- 4. Clean and Standardize Data ---\n",
    "\n",
    "print(\"\\n--- 4. Cleaning and Standardizing ---\")\n",
    "\n",
    "# --- 4a. Standardize CSV Data ---\n",
    "df_csv_clean = df_csv.rename(columns={\n",
    "    'Date': 'Date',\n",
    "    'ProductID': 'ProductID',\n",
    "    'Amount': 'Amount',\n",
    "    'Region': 'Region'\n",
    "})\n",
    "df_csv_clean['Date'] = pd.to_datetime(df_csv_clean['Date'])\n",
    "df_csv_clean = df_csv_clean.drop_duplicates()\n",
    "print(\"CSV data cleaned.\")\n",
    "\n",
    "# --- 4b. Standardize Excel Data ---\n",
    "df_excel_clean = df_excel.rename(columns={\n",
    "    'OrderDate': 'Date',\n",
    "    'ItemCode': 'ProductID',\n",
    "    'Sales': 'Amount',\n",
    "    'Area': 'Region'\n",
    "})\n",
    "df_excel_clean['Date'] = pd.to_datetime(df_excel_clean['Date'])\n",
    "# Handle missing values (dropping the row)\n",
    "df_excel_clean = df_excel_clean.dropna(subset=['Amount'])\n",
    "# Convert Amount to integer (it was float due to NaN)\n",
    "# df_excel_clean['Amount'] = df_excel_clean['Amount'].astype(int)\n",
    "print(\"Excel data cleaned.\")\n",
    "\n",
    "# --- 4c. Standardize JSON Data ---\n",
    "df_json_clean = df_json.rename(columns={\n",
    "    'date': 'Date',\n",
    "    'product_id': 'ProductID',\n",
    "    'total': 'Amount',\n",
    "    'location': 'Region'\n",
    "})\n",
    "df_json_clean['Date'] = pd.to_datetime(df_json_clean['Date'])\n",
    "print(\"JSON data cleaned.\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "\n",
    "# --- 5. Unify Data into a Single DataFrame ---\n",
    "\n",
    "print(\"\\n--- 5. Unifying Data ---\")\n",
    "# Concatenate the clean DataFrames\n",
    "unified_sales_df = pd.concat(\n",
    "    [df_csv_clean, df_excel_clean, df_json_clean],\n",
    "    ignore_index=True  # Resets the index for the new DataFrame\n",
    ")\n",
    "\n",
    "# print(\"\\n--- üî• Final Unified DataFrame üî• ---\")\n",
    "# print(unified_sales_df.to_string()) # .to_string() prints all rows\n",
    "\n",
    "print(\"\\n--- Final Unified Info ---\")\n",
    "unified_sales_df.info()\n",
    "\n",
    "print(\"\\n--- Final Unified Head ---\")\n",
    "print(unified_sales_df.head(9))\n",
    "\n",
    "print(\"\\n--- Final Descriptive Statistics ---\")\n",
    "print(unified_sales_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c91cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Using cached openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Using cached et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Using cached openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Using cached et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Note: The 'io' import is no longer needed when reading from disk.\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1. DEFINE FILE PATHS\n",
    "#    (Adjust these paths if your files are not in the same folder)\n",
    "# ------------------------------------------------------------------\n",
    "CSV_PATH = \"sales_data.csv\"\n",
    "EXCEL_PATH = \"sales_data.xlsx\"\n",
    "JSON_PATH = \"sales_data.json\"\n",
    "\n",
    "# --- 2. LOAD DATA INTO DATAFRAMES FROM EXTERNAL FILES ---\n",
    "\n",
    "print(\"--- 2. Loading Data from External Files ---\")\n",
    "try:\n",
    "    # Load CSV using its file path\n",
    "    df_csv = pd.read_csv(CSV_PATH)\n",
    "\n",
    "    # Load Excel using its file path (requires 'openpyxl' engine)\n",
    "    df_excel = pd.read_excel(EXCEL_PATH, engine='openpyxl')\n",
    "\n",
    "    # Load JSON using its file path\n",
    "    df_json = pd.read_json(JSON_PATH)\n",
    "\n",
    "    print(f\"Successfully loaded data from {CSV_PATH}, {EXCEL_PATH}, and {JSON_PATH}\")\n",
    "\n",
    "    # Display a preview of the loaded data\n",
    "    print(\"\\nInitial CSV Data Head:\\n\", df_csv.head())\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"\\n‚ùå ERROR: File not found. Please ensure the file '{e.filename}' exists in the correct path.\")\n",
    "    # Exit gracefully or handle the error as needed\n",
    "    df_csv, df_excel, df_json = None, None, None\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# The rest of your cleaning and unifying pipeline (Tasks 3, 4, 5)\n",
    "# would follow here, using df_csv, df_excel, and df_json.\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "if df_csv is not None:\n",
    "    print(\"\\nReady for Cleaning and Unification (Tasks 3-5).\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
